# ğŸ” Codebase Audit: Data Import/Export Architecture

## The Critical Gap You Identified

You're absolutely right. I was explaining how Selenium works for the **Dev persona** (PR sync), but that doesn't address the **PO persona's data needs**.

---

## Current State Analysis

### âœ… What EXISTS

#### 1. **Frontend UI for Data Import** (modern-ui.html)
- âœ… "Automation" tab with "Data Imports" section
- âœ… Jira Data Scraper UI (lines 231-287)
  - JQL query input
  - Field selection checkboxes
  - Auto-refresh interval
  - "Import Now" and "Test Connection" buttons
- âœ… Dependency Canvas Data section (lines 289-349)
  - Radio buttons for "From Jira" or "Upload JSON"
  - Project key input
  - JSON file upload option
  - "Load Data" button

#### 2. **GitHub Scraper** (github_scraper.py)
- âœ… Uses Selenium to extract PR data from GitHub
- âœ… Returns structured PR information
- âœ… Finds Jira ticket keys in PR titles

#### 3. **Jira Automator** (jira_automator.py)
- âœ… Uses Selenium to UPDATE Jira tickets
- âœ… Finds elements, clicks buttons, types in fields
- âœ… Changes statuses, adds labels, adds comments

---

### âŒ What's MISSING

#### 1. **No Jira Data Extractor/Scraper**
- âŒ No `jira_scraper.py` or `jira_extractor.py`
- âŒ Can't read features/epics from Jira
- âŒ No way to get feature structure from Jira
- âŒ No JQL query execution via Selenium

#### 2. **No Backend API Handlers**
- âŒ No `/api/jira/import` endpoint
- âŒ No `/api/jira/test-connection` endpoint
- âŒ No `/api/dependency/load` endpoint
- âŒ No handler to save imported data to config

#### 3. **No Data Storage/Processing**
- âŒ No way to parse Jira API response
- âŒ No CSV export/import functionality
- âŒ No JSON structure validation
- âŒ No transformation of Jira data â†’ Waypoint format

#### 4. **No Frontend JavaScript Handlers**
- âŒ "Import Now" button has no click handler
- âŒ "Test Connection" button has no handler
- âŒ "Load Data" button has no handler
- âŒ File upload validation missing
- âŒ Status messages not implemented

---

## User Journey Gaps

### PO Persona: What SHOULD Happen

```
PO: Clicks "Automation" tab
   â”œâ”€â†’ UI shows Jira Data Scraper form
   â”œâ”€â†’ User enters JQL: "project = MYPROJ AND type = Epic"
   â”œâ”€â†’ User clicks "Test Connection"
   â”‚   âŒ MISSING: Backend handler to test Jira connection
   â”‚
   â”œâ”€â†’ User clicks "Import Now"
   â”‚   âŒ MISSING: Backend handler to:
   â”‚       â€¢ Execute JQL query via Selenium
   â”‚       â€¢ Extract features/epics from Jira
   â”‚       â€¢ Parse response
   â”‚       â€¢ Transform to feature structure
   â”‚       â€¢ Save to config or temp storage
   â”‚
   â”œâ”€â†’ User clicks "PO" tab
   â”‚   âœ… UI shows features
   â”‚   âŒ MISSING: Features list is empty (no data source)
   â”‚
   â””â”€â†’ User sees dependency canvas
       âŒ MISSING: No data extraction from Jira
```

---

## What Needs to Be Built

### Phase 1: Jira Data Extraction (Priority 1)

**New file: `jira_scraper.py`**
```python
class JiraScraper:
    """Extract features, epics, and dependencies from Jira"""
    
    def __init__(self, driver, config):
        self.driver = driver
        self.config = config
    
    def execute_jql(self, jql_query):
        """Execute JQL query via Jira web UI and return results"""
        # Navigate to Jira search
        # Enter JQL
        # Parse results
        # Return structured data
    
    def get_epics(self, project_key):
        """Get all epics from project"""
        # JQL: "project = KEY AND type = Epic"
    
    def get_stories(self, epic_key):
        """Get all stories under an epic"""
        # JQL: "parent = EPIC_KEY"
    
    def get_dependencies(self, issue_key):
        """Get dependencies/blockers for issue"""
        # Parse issue links
        # Extract relationships
    
    def get_metrics(self, issue_key):
        """Get metrics (story points, cycle time, etc)"""
        # Parse custom fields
        # Return structured metrics
```

### Phase 2: Backend API Handlers (Priority 1)

**New in `app.py`:**
```python
def _handle_jira_import(self, data):
    """Import features from Jira"""
    # Get JQL query from request
    # Create JiraScraper
    # Execute query
    # Return results
    
def _handle_jira_test_connection(self, data):
    """Test Jira connection"""
    # Try to navigate to Jira
    # Check if authenticated
    # Return status

def _handle_dependency_load(self, data):
    """Load dependency data"""
    # Check if from Jira or JSON
    # Extract data
    # Save to config
```

### Phase 3: Data Transformation (Priority 2)

**New file: `data_transformer.py`**
```python
class DataTransformer:
    """Transform Jira data to Waypoint format"""
    
    def jira_to_features(self, jira_response):
        """Convert Jira epics to feature structure"""
        # Transform: Epic â†’ Feature
        # Group: Stories â†’ Child issues
        # Calculate: Progress, status
        # Return: [{name, key, status, children: [...]}]
    
    def jira_to_dependencies(self, jira_issues):
        """Convert Jira links to dependency structure"""
        # Parse issue links
        # Build dependency graph
        # Identify blockers
        # Return: [{key, blockers: [...]}, ...]
    
    def csv_to_features(self, csv_data):
        """Import from CSV export"""
        # Parse CSV
        # Transform to feature structure
    
    def validate_feature_json(self, json_data):
        """Validate feature JSON structure"""
        # Check required fields
        # Return validation errors
```

### Phase 4: Config Storage (Priority 2)

**Update config.yaml structure:**
```yaml
jira:
  base_url: https://company.atlassian.net
  project_key: MYPROJ
  
data_sources:
  features:
    source: jira  # or 'csv', 'json', 'manual'
    jql_query: "project = MYPROJ AND type = Epic"
    last_import: 2025-12-26T01:15:50Z
    auto_refresh: 60  # minutes
    
  dependencies:
    source: jira  # or 'json'
    project_keys: MYPROJ, SHARED
    issue_limit: 500
    last_import: 2025-12-26T01:15:50Z
    
imported_data:
  features: [...]  # Stored feature structure
  dependencies: [...]  # Stored dependency graph
```

---

## Current Data Flow (What's Broken)

```
PO Wants Features
  â†“
Clicks "Import Now"
  â†“
Frontend sends POST to... NOWHERE âŒ
  â†“
No backend handler
  â†“
Jira data NEVER extracted
  â†“
PO sees empty feature list âŒ
```

---

## What Should Happen

```
PO Wants Features
  â†“
Clicks "Import Now"
  â†“
Frontend sends POST /api/jira/import âœ…
  â†“
Backend: JiraScraper.execute_jql("project = MYPROJ AND type = Epic") âœ…
  â†“
Selenium navigates to Jira âœ…
  â†“
Selenium searches with JQL âœ…
  â†“
Selenium parses HTML results âœ…
  â†“
DataTransformer converts to feature structure âœ…
  â†“
Saves to config.yaml âœ…
  â†“
Frontend updates PO tab âœ…
  â†“
PO sees: Features âœ… + Dependency Canvas âœ… + Metrics âœ…
```

---

## File-by-File Status

### âœ… Files That Exist and Work
- `app.py` - Main backend, but missing handlers
- `modern-ui.html` - UI is there, but no JS handlers
- `github_scraper.py` - Works for GitHub
- `jira_automator.py` - Works for updating Jira
- `sync_engine.py` - Orchestrates sync
- `config.yaml` - Configuration

### âŒ Files That Are Missing
- `jira_scraper.py` - **CRITICAL** - Extract data from Jira
- `data_transformer.py` - Transform to Waypoint format
- `data_validator.py` - Validate imported data
- `csv_parser.py` - Handle CSV imports
- Frontend JavaScript handlers for import buttons

### âŒ Features That Are Missing
- API endpoint: `/api/jira/import`
- API endpoint: `/api/jira/test-connection`
- API endpoint: `/api/dependency/load`
- API endpoint: `/api/features/save`
- JavaScript event handlers for import buttons
- Data validation and error handling
- CSV/JSON file parsing
- Transformation pipeline

---

## The Real User Journey (What You Need)

### For PO Persona

**Step 1: Configure Jira Data Source**
```
User navigates to: Automation â†’ Data Imports â†’ Jira Data Scraper
User enters: JQL = "project = MYPROJ AND type = Epic"
User clicks: "Test Connection"
  â†’ Backend should test Jira auth and connectivity
  
User clicks: "Import Now"
  â†’ Backend should:
    1. Execute JQL via Selenium
    2. Parse results
    3. Extract feature structure
    4. Save to config
    5. Return success status
```

**Step 2: View Features**
```
User navigates to: PO tab
  â†’ Features & Epics section should be POPULATED
  â†’ Shows hierarchical list of imported features
  â†’ Shows progress/status
  â†’ Shows child stories
  
User navigates to: Dependency Canvas
  â†’ Should show dependency graph
  â†’ Should show blockers
  â†’ Interactive visualization
```

**Step 3: Optional - Export to CSV**
```
User clicks: "Export Features"
  â†’ Downloads CSV with current features
User clicks: "Export Dependencies"
  â†’ Downloads CSV with dependency structure
```

---

## What's ACTUALLY in Place vs Missing

| Feature | UI | Backend | Data Flow | Status |
|---------|----|---------|-----------| ------|
| **Jira Data Import** | âœ… Yes | âŒ No | âŒ Broken | **CRITICAL** |
| **Dependency Loading** | âœ… Yes | âŒ No | âŒ Broken | **CRITICAL** |
| **Feature Display** | âœ… Yes | âŒ No data | âŒ Broken | **CRITICAL** |
| **CSV Import** | âŒ No | âŒ No | âŒ Broken | **HIGH** |
| **CSV Export** | âŒ No | âŒ No | âŒ Broken | **HIGH** |
| **Metrics Collection** | âœ… UI exists | âŒ No | âŒ Broken | **MEDIUM** |
| **GitHub Sync** | âœ… Yes | âœ… Yes | âœ… Works | âœ… DONE |
| **Jira Updates** | âœ… Yes | âœ… Yes | âœ… Works | âœ… DONE |

---

## Summary

**The core issue:** The UI exists for PO data import, but there's **zero backend implementation** to extract data from Jira and make it available to the frontend.

**What's needed:**
1. âœ… **Jira Scraper** - Extract features/epics/dependencies
2. âœ… **Backend Handlers** - `/api/jira/import`, `/api/dependency/load`
3. âœ… **Data Transformer** - Convert Jira â†’ Waypoint format
4. âœ… **Config Storage** - Save imported data persistently
5. âœ… **Frontend Handlers** - Wire up import buttons
6. âœ… **CSV Support** - Parse/export CSV files

**Without this:** The PO persona cannot actually use Waypoint to view their features because there's no way to get feature data into the system!

This is exactly what you were pointing out. The UI promises functionality that the backend doesn't support yet.
